{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6b75fe",
   "metadata": {},
   "source": [
    "###  Standard Input, Output, and Error (sys.stdin, sys.stdout, sys.stderr)\n",
    "\n",
    "UNIX users are already familiar with the concept of standard input, standard output, and standard error. This section is for the rest of you. \n",
    "\n",
    "Standard output and standard error (commonly abbreviated stdout and stderr) are pipes that are built into every UNIX system. When you print something, it goes to the stdout pipe; when your program crashes and prints out debugging information (like a traceback in Python), it goes to the stderr pipe. Both of these pipes are ordinarily just connected to the terminal window where you are working, so when a program prints, you see the output, and when a program crashes, you see the debugging information. \n",
    "\n",
    "(If you're working on a system with a window-based Python IDE, stdout and stderr default to your “Interactive Window”.) \n",
    "\n",
    "##### Streaming with sys.stdin, sys.stdout, sys.stderr pipes\n",
    "The interpreter provides three standard file objects, known as standard input, standard output, and standard error, which are available in the sys module as sys.stdin, sys.stdout, and sys.stderr, respectively. \n",
    "\n",
    "    Stdin: is a file object corresponding to the stream of all input characters supplied to the interpreter. \n",
    "    Stdout: is the file object that receives output produced by print. \n",
    "    Stderr: is a file that receives error messages. \n",
    " \n",
    " More often than not, stdin is mapped to the user’s keyboard, whereas stdout and stderr produce text onscreen. \n",
    "\n",
    "stdin, stdout, and stderr are predefined file objects that correspond to Python’s standard input, output, and error streams. You can rebind stdout and stderr to file-like objects (objects that supply a write method that accepts a string argument) to redirect the destination of output and error messages. You can rebind stdin to a file-like object open for reading (one that supplies a readline method returning a string) to redirect the source from which built-in functions raw_input and input read. The original values are available as __stdin__, __stdout__, and __stderr__. File objects are covered in File Objects.\n",
    "Note that because the  standard files are actual file objects, file-objects methods can be used to perform raw I/O with the user on these files. \n",
    "\n",
    "- stdout is used by every print statement. stdout  is a file object with all the output methods of file objects opened in     write mode, such as write and writelines. \n",
    "    \n",
    "- stdin is file object, but with the input methods, such as read, readline, and readlines.\n",
    "    \n",
    "    \n",
    "For example, the following code writes to standard output and reads a line of input from standard input:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd63153a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frank \n",
      "Adjei-Banin[]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.stdout.writelines(\"Frank \\n\")\n",
    "sys.stdout.writelines(\"Adjei-Banin\")\n",
    " \n",
    "#stdin automatically captures the lines above\n",
    "name=sys.stdin.readlines()\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e961f22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name : shine\n",
      "shine\n"
     ]
    }
   ],
   "source": [
    "## Alternatively, the built-in function input(prompt) can read a line of text from stdin and optionally print a prompt: \n",
    "name = input(\"Enter your name : \") \n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc413c",
   "metadata": {},
   "source": [
    "Lines read by raw_input() do not include the trailing newline. This is different than reading directly from sys.stdin where newlines are included in the input text. In Python 3, raw_input() has been renamed to input(). Keyboard interrupts (typically generated by Ctrl+C) result in a KeyboardInterrupt exception that can be caught using an exception handler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1023b",
   "metadata": {},
   "source": [
    "##### Doing Something to Each Line in a File\n",
    "The sys module is most helpful when it comes to dealing with an input file, parsing the text it contains and processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70c5540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 0 lines.\n"
     ]
    }
   ],
   "source": [
    " # For example, the following script counts all the lines in the file that is \"piped in\":\n",
    "\n",
    "# countlines.py  \n",
    "import sys\n",
    "data = sys.stdin.readlines()\n",
    "print (\"Counted\", len(data), \"lines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43e7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be98421c",
   "metadata": {},
   "source": [
    "On Windows or DOS, you'd do:\n",
    "\n",
    "C:\\> type countlines.py | python countlines.py \n",
    "Counted 3 lines.\n",
    "\n",
    "NOTE: On Windows, you can use type instead of cat to display the contents of a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d274afc",
   "metadata": {},
   "source": [
    "##### Filtering\n",
    "The readlines function is useful when implementing simple filter operations. \n",
    "Here are a few examples of such filter operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d6df933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding all lines that start with a #\n",
    "import sys\n",
    "for line in sys.stdin.readlines():\n",
    "    if line[0] == '#':\n",
    "        print (line,)\n",
    "\n",
    "# Note that a final comma is needed after the print statement because the line string already includes a newline \n",
    "#  as its last character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the fourth column of a file (where columns are defined by whitespace)\n",
    "\n",
    "\timport sys, string\n",
    "\tfor line in sys.stdin.readlines():\n",
    "\t    words = string.split(line) \n",
    "\t    if len(words) >= 4:\n",
    "\t        print words[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06894774",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(words[3])? (2344166529.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    print words[3]\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(words[3])?\n"
     ]
    }
   ],
   "source": [
    "# We look at the length of the words list to find if there are indeed at least four words. The last two \n",
    "# lines could also be replaced by the try/except idiom, which is quite common in Python:\n",
    " \n",
    "import sys, string\n",
    "for line in sys.stdin.readlines():\n",
    "    words = string.split(line) \n",
    "    try:\n",
    "        print (words[3])\n",
    "    except IndexError:  # there aren't enough words\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the fourth column of a file, where columns are separated by colons, and lowercasing it\n",
    "\timport sys, string\n",
    "\tfor line in sys.stdin.readlines():\n",
    "\t    words = string.split(line, ':') \n",
    "\t    if len(words) >= 4:\n",
    "\t        print (string.lower(words[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6086b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the first 10 lines, the last 10 lines, and every other line\n",
    "\timport sys, string\n",
    "\tlines = sys.stdin.readlines()\n",
    "\tsys.stdout.writelines(lines[:10])          # first ten lines\n",
    "\tsys.stdout.writelines(lines[-10:])         # last ten lines\n",
    "\tfor lineIndex in range(0, len(lines), 2):  # get 0, 2, 4, ...\n",
    "\t    sys.stdout.write(lines[lineIndex])     # get the indexed line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ac26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting the number of times the word \"Python\" occurs in a file\n",
    "import string\n",
    "text = open(fname).read()\n",
    "print string.count(text, 'Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49730739",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing a list of columns into a list of rows\n",
    "\n",
    "'''\n",
    "In this more complicated example, the task is to \"transpose\" a file; imagine you have a file that looks like:\n",
    " \n",
    "Name:   Willie   Mark   Guido   Mary  Rachel   Ahmed\n",
    "Level:    5       4      3       1     6        4\n",
    "Tag#:    1234   4451   5515    5124   1881    5132\n",
    " \n",
    "And you really want it to look like the following instead:\n",
    "\tName:  Level:  Tag#:\n",
    "\tWillie 5       1234\n",
    "\tMark   4       4451\n",
    "\t...\n",
    "    \n",
    "'''\n",
    "\n",
    "# You could use code like the following:\n",
    "import sys, string\n",
    "lines = sys.stdin.readlines()\n",
    "wordlists = []\n",
    "for line in lines:\n",
    "    words = string.split(line)\n",
    "    wordlists.append(words)\n",
    "for row in range(len(wordlists[0])):\n",
    "    for col in range(len(wordlists)):\n",
    "        print wordlists[col][row] + '\\t',\n",
    "    print\n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "Of course, you should really use much more defensive programming techniques to deal with the possibility \n",
    "that not all lines have the same number of words in them, that there may be missing data, etc. \n",
    "Those techniques are task-specific and are left as an exercise to the reader.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73d5f3",
   "metadata": {},
   "source": [
    "##### Choosing chunk sizes\n",
    "All the preceding examples assume you can read the entire file at once (that's what the readlines call expects). In some cases, however, that's not possible, for example when processing really huge files on computers with little memory, or when dealing with files that are constantly being appended to (such as log files). In such cases, you can use a while/readline combination, where some of the file is read a bit at a time, until the end of file is reached. In dealing with files that aren't line-oriented, you must read the file a character at a time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cca7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# read character by character\n",
    "\twhile 1:\n",
    "\t    next = sys.stdin.read(1)            # read a one-character string\n",
    "\t    if not next:                        # or an empty string at EOF\n",
    "\t        break\n",
    "\t \n",
    "\t       Process character 'next'\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c36097",
   "metadata": {},
   "source": [
    "Notice that the read() method on file objects returns an empty string at end of file, which breaks out of the while loop. \n",
    "Most often, however, the files you'll deal with consist of line-based data and are processed a line at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# read line by line\n",
    "\twhile 1:\n",
    "\t    next = sys.stdin.readline()         # read a one-line string\n",
    "\t    if not next:                        # or an empty string at EOF\n",
    "\t        break\n",
    "\t       Process line 'next'\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad4d5f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Doing Something to a Set of Files Specified on the Command Line\n",
    "Being able to read stdin is a great feature; it's the foundation of the Unix toolset. However, one input is not always enough: many tasks need to be performed on sets of files. This is usually done by having the Python program parse the list of arguments sent to the script as command-line options. For example, if you type:\n",
    "\n",
    "C:\\> python myScript.py input1.txt input2.txt input3.txt output.txt\n",
    "    \n",
    "you might think that myScript.py wants to do something with the first three input files and write a new file, called output.py.  Let's see what the beginning of such a program could look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "inputfilenames, outputfilename = sys.argv[1:-1], sys.argv[-1]\n",
    " \n",
    "for inputfilename in inputfilenames:\n",
    "    inputfile = open(inputfilename, \"r\")\n",
    "    do_something_with_input(inputfile)\n",
    "outputfile = open(outputfilename, \"w\")\n",
    "write_results(outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697fdb86",
   "metadata": {},
   "source": [
    "The second line extracts parts of the argv attribute of the sys module. Recall that it's a list of the words on the command line that called the current program. It starts with the name of the script. So, in the example above, the value of sys.argv is:\n",
    "\n",
    "['myScript.py', 'input1.txt', 'input2.txt', 'input3.txt', 'output.txt']. \n",
    "\n",
    "The script assumes that the command line consists of one or more input files and one output file. So the slicing of the input file names starts at 1 (to skip the name of the script, which isn't an input to the script in most cases), and stops before the last word on the command line, which is the name of the output file. The rest of the script should be pretty easy to understand (but won't work until you provide the do_something_with_input() and write_results() functions).\n",
    "\n",
    "Note that the preceding script doesn't actually read in the data from the files, but passes the file object down to a function to do the real work. Such a function often uses the readlines() method on file objects, which returns a list of the lines in that file. A generic version of do_something_with_input() is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e859418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_something_with_input(inputfile):\n",
    "    for line in inputfile.readlines()\n",
    "        process(line)\n",
    " \n",
    "Processing Each Line of One or More Files:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f78ca0",
   "metadata": {},
   "source": [
    "#### The fileinput Module\n",
    "The combination of this idiom with the preceding one regarding opening each file in the sys.argv[1:] list is so common that Python 1.5 introduced a new module that's designed to help do just this task. It's called fileinput and works like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "for line in fileinput.input():\n",
    "   process(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1a186",
   "metadata": {},
   "source": [
    "\n",
    "The fileinput.input() call parses the arguments on the command line, and if there are no arguments to the script, uses sys.stdin instead. It also provides a bunch of useful functions that let you know which file and line number you're currently manipulating:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput, sys, string\n",
    "# take the first argument out of sys.argv and assign it to searchterm\n",
    "searchterm, sys.argv[1:] = sys.argv[1], sys.argv[2:]\n",
    "for line in fileinput.input():\n",
    "   num_matches = string.count(line, searchterm)\n",
    "   if num_matches:                     # a nonzero count means there was a match\n",
    "       print \"found '%s' %d times in %s on line %d.\" % (searchterm, num_matches, \n",
    "           fileinput.filename(), fileinput.filelineno())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80868085",
   "metadata": {},
   "source": [
    "If this script were called mygrep.py, it could be used as follows:\n",
    " \n",
    "C:\\> python mygrep.py in *.py\n",
    "\tfound 'in' 2 times in countlines.py on line 2.\n",
    "\tfound 'in' 2 times in countlines.py on line 3.\n",
    "\tfound 'in' 2 times in mygrep.py on line 1.\n",
    "\tfound 'in' 4 times in mygrep.py on line 4.\n",
    "\tfound 'in' 2 times in mygrep.py on line 5.\n",
    "\tfound 'in' 2 times in mygrep.py on line 7.\n",
    "\tfound 'in' 3 times in mygrep.py on line 8.\n",
    "\tfound 'in' 3 times in mygrep.py on line 12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da120b",
   "metadata": {},
   "source": [
    "### Filenames and Directories (os, os.path, os.curdir, os.listdir, os.rename)\n",
    "\n",
    "We covered reading existing files in the previous section.\n",
    "There are a lot of tasks, however, that need different kinds of file manipulations, such as directory and path management and removing files. Your two best friends in such cases are the os and os.path modules\n",
    "\n",
    "- os.curdir which returns an operating-system specific string that corresponds to the current directory\n",
    "- os.listdir function (which returns the list of filenames in a specified directory\n",
    "- os.rename function:\n",
    "                       \n",
    "\n",
    "Let's take a typical example: you have lots of files, all of which have a space in their name, and you'd like to replace the spaces with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a33145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os, string\n",
    "if len(sys.argv) == 1:                     # if no filenames are specified,\n",
    "    filenames = os.listdir(os.curdir)      #   use current dir\n",
    "else:                                      # otherwise, use files specified\n",
    "    filenames = sys.argv[1:]               #   on the command line\n",
    "for filename in filenames:\n",
    "    if ' ' in filename:\n",
    "        newfilename = string.replace(filename, ' ', '_')\n",
    "        print (\"Renaming\", filename, \"to\", newfilename, \"...\")\n",
    "        os.rename(filename, newfilename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff6de1",
   "metadata": {},
   "source": [
    "This program works fine, but it reveals a certain Unix-centrism. That is, if you call it with wildcards, such as:\n",
    "\n",
    "\tpython despacify.py *.txt\n",
    "    \n",
    "you find that on Unix machines, it renames all the files with names with spaces in them and that end with .txt. In a DOS-style shell, however, this won't work because the shell normally used in DOS and Windows doesn't convert from*.txt to the list of filenames; it expects the program to do it. This is called globbing, because the * is said to match a glob of characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d9f13",
   "metadata": {},
   "source": [
    "##### Matching Sets of Files: The glob Module\n",
    "The glob module exports a single function, also called glob, which takes a filename pattern and returns a list of all the filenames that match that pattern (in the current working directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, glob, operator\n",
    "print sys.argv[1:]\n",
    "sys.argv = reduce(operator.add, map(glob.glob, sys.argv))\n",
    "print sys.argv[1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97eff6b0",
   "metadata": {},
   "source": [
    "/usr/python/book$ python showglob.py *.py\n",
    " \n",
    "['countlines.py', 'mygrep.py', 'retest.py', 'showglob.py', 'testglob.py']\n",
    "['countlines.py', 'mygrep.py', 'retest.py', 'showglob.py', 'testglob.py'] \n",
    " \n",
    "C:\\python\\book> python showglob.py *.py\n",
    "['*.py']\n",
    "['countlines.py', 'mygrep.py', 'retest.py', 'showglob.py', 'testglob.py']\n",
    " \n",
    "\n",
    "map is a function that takes a callable object (usually a function) and a sequence, calls the callable object with each element of the sequence in turn, and returns a list containing the values returned by the function. For an graphical representation of what map does, see Figure 9-1. [3]\n",
    "Figure 9-1. Graphical representation of the behavior of the map built-in\n",
    "   \n",
    "\n",
    "map is needed here (or something equivalent) because you don't know how many arguments were entered on the command line (e.g., it could have been *.py *.txt *.doc). So the glob.glob function is called with each argument in turn. Each glob.glob call returns a list of filenames that match the pattern. The map operation then returns a lists of lists, which you need to convert to a single list--the combination of all the lists in this list of lists. That means doing list1 + list2 + ... + listN. That's exactly the kind of situation where the reduce function comes in handy.\n",
    "\n",
    "Just as with map, reduce takes a function as its first argument and applies it to the first two elements of the sequence it receives as its second argument. It then takes the result of that call and calls the function again with that result and the next element in the sequence, etc. (See Figure 9-2 for an illustration of reduce.) But wait: you need + applied to a set of things, and + doesn't look like a function (it isn't). So a function is needed that works the same as +. Here's one:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a33e58",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "define myAdd(something, other):\n",
    "    return something + other\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae230f",
   "metadata": {},
   "source": [
    "You would then use reduce(myAdd, map(...)). This works fine, but better yet, you can use the add function defined in the operator module, which does the same thing. The operator module defines functions for every syntactic operation in Python (including attribute-getting and slicing), and you should use those instead of homemade ones for two reasons.\n",
    "\n",
    "First, they've been coded, debugged, and tested by Guido, who has a pretty good track record at writing bugfree code. \n",
    "\n",
    "Second, they're actually C functions, and applying reduce (or map, or filter) to C functions results in much faster performance than applying it to Python functions. \n",
    "\n",
    "This clearly doesn't matter when all you're doing is going through a few hundred files once. If you do thousands of globs all the time, however, speed can become an issue, and now you know how to do it quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae09966",
   "metadata": {},
   "source": [
    "##### Filter, Map, Reduce built-in function\n",
    "\n",
    "The filter built-in function, like map and reduce, takes a function and a sequence as arguments. It returns the subset of the elements in the sequence for which the specified function returns something that's true. To find all of the even numbers in a set, type this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Or, if you wanted to find all the words in a file that are at least 10 characters long, you could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0187c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numbers = range(30)\n",
    "def even(x):\n",
    "     return x % 2 == 0\n",
    "\n",
    "print (numbers)\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \n",
    "21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    " \n",
    "print (filter(even, numbers))\n",
    "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Or, if you wanted to find all the words in a file that are at least 10 characters long, you could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\timport string\n",
    "\twords = string.split(open('myfile.txt').read())   # get all the words\n",
    "\t \n",
    "\tdef at_least_ten(word): \n",
    "\t    return len(word) >= 10\n",
    "\tlongwords = filter(at_least_ten, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413c414",
   "metadata": {},
   "source": [
    "For a graphical representation of what filter does, see Figure 9-3. One nice special feature of filter is that if one passes None as the first argument, it filters out all false entries in the sequence. So, to find all the nonempty lines in a file called myfile.txt, do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('myfile.txt').readlines()\n",
    "lines = filter(None, lines)       # remember, the empty string is false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c961ffd",
   "metadata": {},
   "source": [
    "map, filter, and reduce are three powerful constructs, and they're worth knowing about; however, they are never necessary. It's fairly simple to write a Python function that does the same thing as any of them. The built-in versions are just as fast, especially when operating on built-in functions written in C, such as the functions in the operator module.\n",
    "\n",
    "Figure 9-3. Graphical representation of the behavior of the filter built-in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f57952",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map/Reduce  functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapper.py:\n",
    "#Generally speaking, iterators and generators (functions that create iterators, for example #with Python’s yield statement) have the advantage that an element of a sequence is not #produced until you actually need it. This can help a lot in terms of computational #expensiveness or memory consumption depending on the task at hand.\n",
    " \n",
    "\"\"\"A more advanced Mapper, using Python iterators and generators.\"\"\"\n",
    " \n",
    "import sys\n",
    " \n",
    "def read_input(file):\n",
    "    for line in file:\n",
    "        # split the line into words\n",
    "        yield line.split()\n",
    " \n",
    "def main(separator='\\t'):\n",
    "    # input comes from STDIN (standard input)\n",
    "    data = read_input(sys.stdin)\n",
    "    for words in data:\n",
    "        # write the results to STDOUT (standard output);\n",
    "\t# what we output here will be the input for the Reduce step, i.e. the input for    #reducer.py\n",
    "        # tab-delimited; the trivial word count is 1\n",
    "        for word in words:\n",
    "            print '%s%s%d' % (word, separator, 1)\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49888f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Reducer.py:\n",
    "#!/usr/bin/env python\n",
    "\"\"\"A more advanced Reducer, using Python iterators and generators.\"\"\"\n",
    " \n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import sys\n",
    " \n",
    "def read_mapper_output(file, separator='\\t'):\n",
    "    for line in file:\n",
    "        yield line.rstrip().split(separator, 1)\n",
    " \n",
    "def main(separator='\\t'):\n",
    "    # input comes from STDIN (standard input)\n",
    "    data = read_mapper_output(sys.stdin, separator=separator)\n",
    "    # groupby groups multiple word-count pairs by word,\n",
    "    # and creates an iterator that returns consecutive keys and their group:\n",
    "    #   current_word - string containing a word (the key)\n",
    "    #   group - iterator yielding all [\"&lt;current_word&gt;\", \"&lt;count&gt;\"] items\n",
    "    for current_word, group in groupby(data, itemgetter(0)):\n",
    "        try:\n",
    "            total_count = sum(int(count) for current_word, count in group)\n",
    "            print \"%s%s%d\" % (current_word, separator, total_count)\n",
    "        except ValueError:\n",
    "            # count was not a number, so silently discard this item\n",
    "            pass\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a89cc",
   "metadata": {},
   "source": [
    "##### Using Temporary Files\n",
    "If you've ever written a shell script and needed to use intermediary files for storing the results of some intermediate stages of processing, you probably suffered from directory litter. You started out with 20 files called log_001.txt,log_002.txt etc., and all you wanted was one summary file called log_sum.txt. In addition, you had a whole bunch of log_001.tmp, log_001.tm2, etc. files that, while they were labeled temporary, stuck around. At least that's what we've seen happen in our own lives. To put order back into your directories, use temporary files in specific directories and clean them up afterwards.\n",
    "To help in this temporary file-management problem, Python provides a nice little module called tempfile that publishes two functions: mktemp() and TemporaryFile(). The former returns the name of a file not currently in use in a directory on your computer reserved for temporary files (such as /tmp on Unix or C:\\TMP on Windows). The latter returns a new file object directly. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d51358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input file\n",
    "inputFile = open('input.txt', 'r')\n",
    "\n",
    "import tempfile\n",
    "# create temporary file\n",
    "tempFile = tempfile.TemporaryFile()                   # we don't even need to \n",
    "first_process(input = inputFile, output = tempFile)   # know the filename...\n",
    " \n",
    "# create final output file\n",
    "outputFile = open('output.txt', 'w')\n",
    "second_process(input = tempFile, output = outputFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10400d11",
   "metadata": {},
   "source": [
    "\n",
    "Using tempfile.TemporaryFile() works well in cases where the intermediate steps manipulate file objects. One of its nice features is that when it's deleted, it automatically deletes the file it created on disk, thus cleaning up after itself. One important use of temporary files, however, is in conjunction with the os.system call, which means using a shell, hence using filenames, not file objects. For example, let's look at a program that creates form letters and mails them to a list of email addresses (on Unix only):\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "617a1fd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1491165958.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Using tempfile.TemporaryFile() works well in cases where the intermediate steps manipulate file objects. One of its nice features is that when it's deleted, it automatically deletes the file it created on disk, thus cleaning up after itself. One important use of temporary files, however, is in conjunction with the os.system call, which means using a shell, hence using filenames, not file objects. For example, let's look at a program that creates form letters and mails them to a list of email addresses (on Unix only):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "formletter = \"\"\"Dear %s,\\nI'm writing to you to suggest that ...\"\"\"    # etc. \n",
    "myDatabase = [('Bill Clinton', 'bill@whitehouse.gov.us'),\n",
    "              ('Bill Gates', 'bill@microsoft.com'),\n",
    "              ('Bob', 'bob@subgenius.org')]\n",
    "for name, email in myDatabase:\n",
    "    specificLetter = formletter % name\n",
    "    tempfilename = tempfile.mktemp()\n",
    "    tempfile = open(tempfilename, 'w')\n",
    "    tempfile.write(specificLetter)\n",
    "    tempfile.close()\n",
    "    os.system('/usr/bin/mail %(email)s -s \"Urgent!\" < %(tempfile)s' % vars()) \n",
    "    os.remove(tempfilename)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bcfab",
   "metadata": {},
   "source": [
    "The first line in the for loop returns a customized version of the form letter based on the name it's given. That text is then written to a temporary file that's emailed to the appropriate email address using the os.system call (which we'll cover later in this chapter). Finally, to clean up, the temporary file is removed. If you forgot how the % bit works, go back to Chapter 2 and review it; it's worth knowing. The vars() function is a built-in function that returns a dictionary corresponding to the variables defined in the current local namespace. The keys of the dictionary are the variable names, and the values of the dictionary are the variable values. vars() comes in quite handy for exploring namespaces. It can also be called with an object as an argument (such as a module, a class, or an instance), and it will return the namespace of that object. Two other built-ins, locals() and globals(), return the local and global namespaces, respectively. In all three cases, modifying the returned dictionaries doesn't guarantee any effect on the namespace in question, so view these as read-only and you won't be surprised. You can see that the vars() call creates a dictionary that is used by the string interpolation mechanism; it's thus important that the names inside the %(...)s bits in the string match the variable names in the program.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040fe0e3",
   "metadata": {},
   "source": [
    "##### More on Scanning Text Files\n",
    "Suppose you've run a program that stores its output in a text file, which you need to load. The program creates a file that's composed of a series of lines that each contain a value and a key separated by whitespace:\n",
    "\tvalue key\n",
    "\tvalue key\n",
    "\tvalue key\n",
    "\tand so on...\n",
    " \n",
    "A key can appear on more than one line in the file, and you'd probably like to collect all the values that appear for each given key as you scan the file. Here's one way to solve this problem:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166bc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = {}\n",
    "for line in open(sys.argv[1], 'r').readlines():\n",
    "    left, right = string.split(line)    \n",
    "    try:                                \n",
    "        entries[right].append(left)       # extend list\n",
    "    except KeyError:\n",
    "        entries[right] = [left]           # first time seen\n",
    " \n",
    "for (right, lefts) in entries.items():\n",
    "  print \"%04d '%s'\\titems => %s\" % (len(lefts), right, lefts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e848354",
   "metadata": {},
   "source": [
    "\n",
    "This script uses the readlines method to scan the text file line by line, and calls the built-in string.split function to chop the line into a list of substrings--a list containing the value and key strings separated by blanks or tabs in the file. To store all occurrences of a key, the script uses a dictionary called entries. The try statement in the loop tries to add new values to an existing entry for a key; if no entry exists for the key, it creates one. Notice that the trycould be replaced with an if here:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c35743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys, string\n",
    " \n",
    "if entries.has_key(right):        # is it already in the dictionary?\n",
    "    entries[right].append(left)   # add to the list of current values for key\n",
    "else:\n",
    "    entries[right] = [left]       # initialize key's values list\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21199634",
   "metadata": {},
   "source": [
    "Testing whether a dictionary contains a key is sometimes faster than catching an exception with the try technique; it depends on how many times the test is true. Here's an example of this script in action. The input filename is passed in as a command-line argument (sys.argv[1]):\n",
    "\n",
    "\t% cat data.txt\n",
    "\t1       one\n",
    "\t2       one\n",
    "\t3       two\n",
    "\t7       three\n",
    "\t8       two\n",
    "\t10      one\n",
    "\t14      three\n",
    "\t19      three\n",
    "\t20      three\n",
    "\t30      three\n",
    "\t \n",
    "\t% python collector1.py data.txt\n",
    "\t0003 'one'      items => ['1', '2', '10']\n",
    "\t0005 'three'    items => ['7', '14', '19', '20', '30']\n",
    "\t0002 'two'      items => ['3', '8']\n",
    " \n",
    " \n",
    "You can make this code more useful by packaging the scanner logic in a function that returns the entries dictionary as a result and wrapping the printing loop logic at the bottom in an if test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, string\n",
    " \n",
    "def collect(file):\n",
    "    entries = {}\n",
    "    for line in file.readlines():\n",
    "        left, right = string.split(line)    \n",
    "        try:                                \n",
    "            entries[right].append(left)           # extend list\n",
    "        except KeyError:\n",
    "            entries[right] = [left]               # first time seen\n",
    "    return entries\n",
    " \n",
    "if __name__ == \"__main__\":                        # when run as a script\n",
    "    if len(sys.argv) == 1:\n",
    "        result = collect(sys.stdin)               # read from stdin stream\n",
    "    else:\n",
    "        result = collect(open(sys.argv[1], 'r'))  # read from passed filename\n",
    "    for (right, lefts) in result.items():\n",
    "        print \"%04d '%s'\\titems => %s\" % (len(lefts), right, lefts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67af4ec",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "This way, the program becomes a bit more flexible. By using the if _ _name_ _ == \"_ _main_ _\" trick, you can still run it as a top-level script (and get a display of the results), or import the function it defines and process the resulting dictionary explicitly:\n",
    "\n",
    " run as a script file\n",
    "\t% collector2.py < data.txt\n",
    "    \n",
    "\tresult displayed here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3271f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use in some other component (or interactively)\n",
    "from collector2 import collect\n",
    "result = collect(open(\"spam.txt\", \"r\"))\n",
    "\n",
    "process result here...\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc1956",
   "metadata": {},
   "source": [
    "\n",
    "Since the collect function accepts an open file object, it also works on any object that provides the methods (i.e., interface) built-in files do. For example, if you want to read text from a simple string, wrap it in a class that implements the required interface and pass an instance of the class to the collect function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab1131a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'collector2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollector2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mStringIO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m StringIO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 one\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2 one\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3 two\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'collector2'"
     ]
    }
   ],
   "source": [
    "from collector2 import collect\n",
    "from StringIO import StringIO\n",
    "\n",
    "str = StringIO(\"1 one\\n2 one\\n3 two\")\n",
    "result = collect(str)                  # scans the wrapped string\n",
    "print (result)                          # {'one':['1','2'],'two':['3']}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b8901",
   "metadata": {},
   "source": [
    "This code uses the StringIO class in the standard Python library to wrap the string into an instance that has all the methods file objects have; see the Library Reference for more details on StringIO. You could also write a different class or subclass from StringIO if you need to modify its behavior. Regardless, the collect function happily reads text from the string str, which happens to be an in-memory object, not a file.\n",
    "\n",
    "The main reason all this works is that the collect function was designed to avoid making assumptions about the type of object its file parameter references. As long as the object exports a readlines method that returns a list of strings, collect doesn't care what type of object it processes. The interface is all that matters. This runtime binding[4] is an important feature of Python's object system, and allows you to easily write component programs that communicate with other components. \n",
    "\n",
    "For instance, consider a program that reads and writes satellite telemetry data using the standard file interface. By plugging in an object with the right sort of interface, you can redirect its streams to live sockets, GUI boxes, web interfaces, or databases without changing the program itself or even recompiling it.\n",
    "\n",
    "From <https://d.docs.live.net/1a1d9be9f87fd2f7/BI/python/DEEP%20Dives_FileSystem%20Input%20and%20Output.docx> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
